{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "os.chdir('/Users/bebr1814/projects/wikipedia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikipediaGame:\n",
    "\tdef __init__(self, wiki_xml_path=None, graph_pkl=None):\n",
    "\n",
    "\t\tself.exclude_prefixes = ['Module:', 'Template:', 'Wikipedia:', 'MediaWiki:', 'Category:', 'File:', 'Help:', 'Portal:', 'Draft:', 'Book:', 'User:', 'Special:', 'TimedText:', 'Talk:', 'Wikipedia talk:', 'MediaWiki talk:', 'Category talk:', 'File talk:', 'Template talk:', 'Module talk:']\n",
    "\n",
    "\t\t# DB to store text\n",
    "\t\tself.lmdb_path = \"wikipedia_db\"\n",
    "\t\tif os.path.exists(self.lmdb_path) and graph_pkl is None:\n",
    "\t\t\tshutil.rmtree(self.lmdb_path, ignore_errors=True) # delete LMDB database if it exists\n",
    "\t\tself.lmdb_env = lmdb.open(self.lmdb_path, map_size=20**9)  # 2GB max size\n",
    "\n",
    "\t\t# DB to store vectors\n",
    "\t\t# This should be generated beforehand\n",
    "\t\tself.vec_lmdb_path = \"vector_db\"\n",
    "\t\tif os.path.exists(self.vec_lmdb_path):\n",
    "\t\t\tself.vec_env = lmdb.open(self.vec_lmdb_path, readonly=True, lock=False)\n",
    "\t\telse:\n",
    "\t\t\tself.vec_env = None\n",
    "\n",
    "\n",
    "\t\tif graph_pkl is not None:\n",
    "\t\t\tself.G = pickle.load(open(graph_pkl, \"rb\"))\n",
    "\t\t\tself.article_titles = set(self.G.nodes())\n",
    "\t\telif wiki_xml_path is not None:\n",
    "\t\t\tself.wiki_xml = wiki_xml_path\n",
    "\t\t\tself.build_graph()\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Either wiki_xml_path or graph must be provided\")\n",
    "\n",
    "\t\tself.pagerank = nx.pagerank(self.G, alpha=0.85)\n",
    "\t\tself.betweenness = None\n",
    "\t\t# nx.betweenness_centrality(self.G, normalized=True, k=1000)\n",
    "\n",
    "\tdef store_article(self,title, content):\n",
    "\t\twith self.lmdb_env.begin(write=True) as txn:\n",
    "\t\t\ttxn.put(title.encode(), content.encode())  # Store title â†’ full text\n",
    "\n",
    "\tdef get_article(self,title):\n",
    "\t\twith self.lmdb_env.begin() as txn:\n",
    "\t\t\tdata = txn.get(title.encode())\n",
    "\t\t\treturn data.decode() if data else None  # Retrieve full text by title\n",
    "\t\n",
    "\tdef get_vector(self, title):\n",
    "\t\tif self.vec_env is None:\n",
    "\t\t\traise RuntimeError(\"Vector LMDB is not initialized. Make sure vector_db exists.\")\n",
    "\n",
    "\t\twith self.vec_env.begin() as txn:\n",
    "\t\t\tdata = txn.get(title.encode())\n",
    "\t\t\tif data is None:\n",
    "\t\t\t\treturn None\n",
    "\t\t\treturn np.frombuffer(data, dtype=np.float32)\n",
    "\n",
    "\tdef build_graph(self):\n",
    "\t\t\"\"\"Build the directed graph from Wikipedia XML.\"\"\"\n",
    "\t\tprint(\"Parsing XML...\")\n",
    "\t\ttree = ET.parse(self.wiki_xml)\n",
    "\t\troot = tree.getroot()\n",
    "\t\t\n",
    "\t\t# Initialize a directed graph\n",
    "\t\tself.G = nx.DiGraph()\n",
    "\t\tself.article_titles = set()\n",
    "\t\t\n",
    "\t\tprint(\"Building graph and extracting text content...\")\n",
    "\n",
    "\t\t# get all article titles\n",
    "\t\tfor page in tqdm(root[1:]):\n",
    "\t\t\ttitle = page.find('{http://www.mediawiki.org/xml/export-0.11/}title').text\n",
    "\t\t\tif any(title.startswith(prefix) for prefix in self.exclude_prefixes) or title in ['Global']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tself.article_titles.add(title)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# Iterate over the XML tree\n",
    "\t\tfor page in tqdm(root[1:]):\n",
    "\t\t\t# Get the title of the page\n",
    "\t\t\ttitle = page.find('{http://www.mediawiki.org/xml/export-0.11/}title').text\n",
    "\t\t\tif any(title.startswith(prefix) for prefix in self.exclude_prefixes):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# Get the text of the page\n",
    "\t\t\ttext_element = page.find('{http://www.mediawiki.org/xml/export-0.11/}revision').find('{http://www.mediawiki.org/xml/export-0.11/}text')\n",
    "\t\t\t\n",
    "\t\t\tif text_element is not None:\n",
    "\n",
    "\t\t\t\ttext = text_element.text\n",
    "\t\t\t\tif text is None or text == '':\n",
    "\t\t\t\t\tself.article_titles.remove(title)\n",
    "\t\t\t\t\t# Remove any links to this article from the graph\n",
    "\t\t\t\t\tif self.G.has_node(title):\n",
    "\t\t\t\t\t\tself.G.remove_node(title)\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# Store the text content in the LMDB database\n",
    "\t\t\t\tself.store_article(title, self.clean_wikipedia_text(text))\n",
    "\n",
    "\t\t\t\t# Find all links in the text using regex\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tlinks = re.findall(r'\\[\\[([^|\\]]+)(?:\\|[^\\]]*)?\\]\\]', text)\n",
    "\t\t\t\t\t# Exclude links that aren't valid articles\n",
    "\t\t\t\t\tlinks = list(self.article_titles.intersection(links))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Add the links to the graph\n",
    "\t\t\t\t\tif len(links) > 0:\n",
    "\t\t\t\t\t\tfor link in links:\n",
    "\t\t\t\t\t\t\tself.G.add_edge(title, link)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Add the node even if it has no outgoing links\n",
    "\t\t\t\t\t\tself.G.add_node(title)\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"{title} processing error: {e}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f\"{title} has no text content\")\n",
    "\t\t\n",
    "\t\t# print(\"Vectorizing all articles...\")\n",
    "\t\t# self.vectorize_all()\n",
    "\t\t\n",
    "\t\tprint(f\"Graph built with {len(self.G.nodes())} nodes and {len(self.G.edges())} edges\")\n",
    "\t\n",
    "\tdef clean_wikipedia_text(self,text):\n",
    "\t\t\n",
    "\t\t# Remove {{templates}}\n",
    "\t\ttext = re.sub(r\"\\{\\{.*?\\}\\}\", \"\", text)\n",
    "\n",
    "\t\t# Remove [[File:...]] and similar media references\n",
    "\t\ttext = re.sub(r\"\\[\\[File:.*?\\]\\]\", \"\", text)\n",
    "\n",
    "\t\t# Remove section headers (== Title ==)\n",
    "\t\ttext = re.sub(r\"==+.*?==+\", \"\", text)\n",
    "\n",
    "\t\t# Remove [[Category:...]] tags (if present in raw text)\n",
    "\t\ttext = re.sub(r\"\\[\\[Category:.*?\\]\\]\", \"\", text)\n",
    "\n",
    "\t\t# Replace [[linked text|display text]] with just \"display text\"\n",
    "\t\ttext = re.sub(r\"\\[\\[([^|\\]]+\\|)?([^\\]]+)\\]\\]\", r\"\\2\", text)\n",
    "\n",
    "\t\t# Remove all remaining [[brackets]] (if any)\n",
    "\t\ttext = re.sub(r\"\\[\\[|\\]\\]\", \"\", text)\n",
    "\n",
    "\t\t# Remove extra whitespace and newlines\n",
    "\t\ttext = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\t\t# Remove \\'\n",
    "\t\ttext = text.replace(\"\\'\", \"\")\n",
    "\t\t\n",
    "\t\treturn text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_game = WikipediaGame(wiki_xml_path='/Users/bebr1814/projects/wikipedia/data/simplewiki-20250301-pages-articles-multistream.xml')\n",
    "\n",
    "# with open('/Users/bebr1814/projects/wikipedia/pickles/simplewiki_full_graph.4.15.25.pkl', 'wb') as f:\n",
    "# \tpickle.dump(wiki_game.G, f)\n",
    "\n",
    "# with open('/Users/bebr1814/projects/wikipedia/pickles/simplewiki_full_graph.betweenness.pkl', 'wb') as f:\n",
    "# \tpickle.dump(wiki_game.betweenness, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_game = WikipediaGame(graph_pkl='/Users/bebr1814/projects/wikipedia/pickles/simplewiki_full_graph.4.15.25.pkl')\n",
    "wiki_game.betweenness = pickle.load(open('/Users/bebr1814/projects/wikipedia/pickles/simplewiki_full_graph.betweenness.pkl', \"rb\"))\n",
    "\n",
    "pairs = pd.read_csv('test_pairs.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thumb|right|The SELinux administrator in Fedora (operating system)|Fedora 8 Security-Enhanced Linux (SELinux) is a Linux feature that gives a variety of security rules, including mandatory access controls. It does so by using Linux Security Modules (LSM) in the Linux kernel. It is not a Linux distribution, but rather a group of changes that can be used on Unix-like operating systems, such as Linux and BSD.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_game.get_article('Security-Enhanced Linux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.49591449e-02, -1.25363609e-02, -3.64816152e-02,  2.78028892e-05,\n",
       "        1.36486918e-01, -1.76118240e-02,  2.41619255e-02,  9.86313745e-02,\n",
       "       -5.06293215e-02, -7.80712590e-02,  5.96723147e-02,  4.46877219e-02,\n",
       "       -3.04713864e-02, -5.81546575e-02,  1.98160820e-02, -3.48866954e-02,\n",
       "        2.83649862e-02,  1.21961646e-02, -5.96932024e-02, -5.53695932e-02,\n",
       "       -5.65569848e-03, -3.29952687e-02, -2.79037207e-02,  1.22546228e-02,\n",
       "       -3.64687219e-02, -4.65247557e-02, -7.60664865e-02, -1.89227343e-03,\n",
       "        4.52343002e-02, -6.43991530e-02, -3.10904514e-02,  1.65180210e-02,\n",
       "        4.04766388e-02,  2.99598416e-03, -7.12891668e-02,  2.81087626e-02,\n",
       "        6.86487332e-02, -6.00882582e-02, -6.71593100e-02, -8.08424607e-04,\n",
       "       -9.04838741e-02, -3.30148414e-02, -6.97469041e-02, -1.38829984e-02,\n",
       "       -5.22204265e-02, -1.19845215e-02,  3.16130742e-02, -2.52068564e-02,\n",
       "       -1.32169481e-02,  2.07248274e-02,  3.64207849e-02,  6.13596886e-02,\n",
       "        4.16596308e-02,  5.64924553e-02, -2.25115661e-02, -6.64710999e-02,\n",
       "       -7.80013809e-03, -1.61202196e-02,  3.89528200e-02,  6.15728833e-02,\n",
       "       -1.49539420e-02,  1.77216586e-02, -7.70714581e-02,  7.66090080e-02,\n",
       "       -9.46443249e-03, -4.35076244e-02,  3.71703831e-03, -6.46592528e-02,\n",
       "       -1.59714033e-03, -4.06954959e-02, -1.38289379e-02, -6.17587902e-02,\n",
       "        2.44579166e-02,  1.55615546e-02, -1.78710595e-02, -2.69679744e-02,\n",
       "       -6.17676787e-02, -7.14553334e-03,  2.54873913e-02,  2.27773692e-02,\n",
       "       -1.08525138e-02,  9.81598347e-02,  3.79212052e-02, -2.07160078e-02,\n",
       "       -1.72267389e-02,  6.06413707e-02, -1.86766740e-02,  2.90140621e-02,\n",
       "        4.33561243e-02,  3.73222455e-02,  7.90359676e-02,  1.26802325e-02,\n",
       "        2.58137695e-02, -3.08769718e-02,  1.14385784e-02,  2.82707321e-03,\n",
       "        4.17341180e-02, -2.41565704e-02, -3.42354253e-02,  4.81863618e-02,\n",
       "       -3.54763754e-02, -4.31054123e-02, -7.38442317e-02,  4.34322953e-02,\n",
       "       -1.36548029e-02,  1.25128999e-02, -2.19891709e-03, -6.39647478e-03,\n",
       "       -6.59693107e-02, -5.58924116e-02,  4.55583930e-02,  3.79070491e-02,\n",
       "        2.12275870e-02, -3.82903405e-02,  7.24914204e-03, -3.08448672e-02,\n",
       "        3.90205439e-03, -9.86788142e-03,  5.54549210e-02,  1.66708827e-02,\n",
       "        2.75772642e-02, -8.52520671e-03,  4.41808850e-02, -6.60637300e-03,\n",
       "        5.41744418e-02,  1.54895680e-02, -9.83161703e-02, -5.60942173e-35,\n",
       "        4.19317223e-02,  2.17589680e-02, -6.54161572e-02, -4.78779040e-02,\n",
       "        2.62047928e-02,  8.22923705e-03, -4.07716595e-02, -1.34868473e-02,\n",
       "       -1.06083125e-01,  1.02705084e-01,  2.89012510e-02,  3.73151898e-02,\n",
       "        3.04737259e-02, -6.20679706e-02,  1.05081536e-01,  1.91935357e-02,\n",
       "        1.00414455e-02, -4.83824350e-02,  8.76783580e-02,  9.66370013e-03,\n",
       "        4.15691249e-02,  2.64729075e-02,  5.98807726e-03,  3.61003354e-02,\n",
       "        3.51873711e-02,  1.06804678e-02,  2.82257292e-02,  1.69109646e-03,\n",
       "        3.09990849e-02,  2.79430039e-02, -7.86582753e-02, -1.09937536e-02,\n",
       "       -1.17802871e-02,  7.69069837e-03,  3.33920009e-02, -4.46387455e-02,\n",
       "       -1.09998500e-02, -2.25855075e-02, -2.23866594e-03, -7.19306394e-02,\n",
       "        2.42084768e-02,  1.12226547e-03, -2.68417951e-02, -2.90665049e-02,\n",
       "        3.56494375e-02, -1.11654820e-02,  6.47115381e-03,  1.21047972e-02,\n",
       "        8.42668787e-02, -2.17711702e-02, -4.81729619e-02, -2.72973394e-03,\n",
       "        1.10658966e-01, -7.41882101e-02,  3.52927186e-02, -3.92811485e-02,\n",
       "       -7.72151947e-02, -1.26588596e-02, -3.14524733e-02,  9.63190645e-02,\n",
       "        6.94238441e-03,  2.28950270e-02, -9.58359335e-03, -6.80080336e-03,\n",
       "       -1.50197521e-02, -3.25377546e-02, -4.48684357e-02, -1.96316279e-02,\n",
       "        7.21414313e-02,  2.51120627e-02, -1.41295701e-01, -1.93430937e-03,\n",
       "       -4.70126420e-02,  1.39082417e-01, -6.23315051e-02, -5.94042987e-02,\n",
       "        2.53578760e-02,  1.25560155e-02,  5.34447879e-02,  4.15825704e-03,\n",
       "       -4.84819151e-02,  2.29006559e-02,  2.07467768e-02,  6.59385100e-02,\n",
       "       -1.30628403e-02, -3.09628677e-02, -1.06892020e-01,  7.43563846e-02,\n",
       "       -3.81051388e-04, -6.92703202e-02,  5.47880270e-02, -6.57640249e-02,\n",
       "        1.04709812e-01,  7.83480704e-02, -1.04735047e-01, -2.46130628e-33,\n",
       "       -6.35023341e-02, -8.62340555e-02, -3.74006890e-02, -5.24935089e-02,\n",
       "       -3.11706010e-02,  9.95507464e-02, -6.86548725e-02, -1.46236951e-02,\n",
       "        2.30625551e-02,  1.99024249e-02, -1.50844036e-02,  6.45876378e-02,\n",
       "        5.09320945e-02, -5.84407151e-02,  1.26408983e-03, -4.35449593e-02,\n",
       "       -6.50610998e-02, -5.85313849e-02, -6.57617077e-02, -1.04593318e-02,\n",
       "       -1.32018015e-01,  8.62759575e-02,  1.03393674e-01,  6.64492026e-02,\n",
       "        2.97840443e-02,  1.61117930e-02, -8.50025117e-02,  4.38133553e-02,\n",
       "       -9.17763710e-02,  4.64384146e-02,  5.40698692e-02, -8.90197605e-02,\n",
       "       -3.92200388e-02,  1.58181526e-02, -1.42687885e-02, -8.12250674e-02,\n",
       "       -2.70173363e-02,  2.81712320e-02, -1.05347838e-02,  5.21503314e-02,\n",
       "        3.21028084e-02,  6.19108342e-02,  6.22960664e-02,  1.64470971e-02,\n",
       "       -2.56488174e-02,  2.08174679e-02, -7.75467306e-02, -1.41998101e-03,\n",
       "       -6.59378096e-02, -3.38514894e-02, -1.76655091e-02, -5.74696921e-02,\n",
       "        1.10122263e-01, -3.53864841e-02, -3.43898162e-02, -1.85072385e-02,\n",
       "       -4.88525722e-03,  3.12808603e-02,  6.30212948e-02,  1.04293659e-01,\n",
       "        8.93528312e-02, -3.86887640e-02, -5.14495447e-02,  9.29769799e-02,\n",
       "       -2.42446214e-02,  5.17823733e-03, -1.10046342e-01,  2.68221218e-02,\n",
       "        2.17783507e-02,  6.61264956e-02,  8.37134346e-02, -3.31231058e-02,\n",
       "       -1.33207515e-02,  4.13433313e-02,  4.89705689e-02, -3.78230847e-02,\n",
       "        3.35897245e-02, -6.51993230e-02, -1.00544445e-01,  4.51207347e-02,\n",
       "        2.74677984e-02, -2.66663060e-02, -3.73181142e-02,  6.32094219e-02,\n",
       "       -1.80995166e-02, -3.06195561e-02, -1.37466406e-02, -6.60841987e-02,\n",
       "        7.09572509e-02,  5.85338939e-03, -8.29760730e-03, -1.24304406e-02,\n",
       "       -7.16723502e-02,  6.52470812e-02,  2.94515658e-02, -3.50594149e-08,\n",
       "        7.17100725e-02, -7.62714967e-02,  6.55438984e-03, -3.06322500e-02,\n",
       "        2.79714223e-02, -4.04116744e-03,  2.07393970e-02, -8.30081031e-02,\n",
       "       -3.63885760e-02,  6.37585158e-03,  2.32735109e-02,  3.07357591e-02,\n",
       "       -1.58735011e-02, -1.23444490e-01,  4.71942872e-02,  2.91122105e-02,\n",
       "        1.07854158e-02,  1.32165670e-01, -1.93026979e-02,  2.90622786e-02,\n",
       "        5.71906380e-02, -7.77258724e-02, -2.08001677e-02,  7.11916238e-02,\n",
       "        1.86542403e-02,  1.16243958e-02,  8.14751387e-02, -1.37551390e-02,\n",
       "        8.42816606e-02,  9.61371511e-02, -2.84591336e-02, -1.66544793e-04,\n",
       "        7.06173014e-03,  5.66157214e-02, -9.69319325e-03,  5.53796142e-02,\n",
       "       -9.27759930e-02, -2.25081258e-02,  3.08320479e-04,  9.21263080e-03,\n",
       "       -8.03897157e-03,  2.77878642e-02,  3.31496038e-02,  2.63446346e-02,\n",
       "       -1.46518037e-01, -1.43714445e-02,  2.21824925e-03, -4.38717641e-02,\n",
       "        9.35079232e-02, -2.43865959e-02,  8.94391164e-02, -2.84027192e-03,\n",
       "       -3.51361893e-02,  1.33634314e-01, -2.73726648e-03, -2.84753237e-02,\n",
       "       -2.46359129e-02, -5.46964537e-03, -1.09546247e-03, -4.62221429e-02,\n",
       "       -4.45404061e-04,  3.00615262e-02,  9.71092656e-02, -8.65072105e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_game.get_vector('Security-Enhanced Linux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4714490703565305e-06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_game.betweenness['Security-Enhanced Linux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacklist = []\n",
    "# for title in wiki_game.article_titles:\n",
    "# \tif wiki_game.get_article(title) is None:\n",
    "# \t\tblacklist.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_path_stats(source, target, wiki_game):\n",
    "\t\"\"\"\n",
    "\tGenerate a dataframe containing statistics for the top 20 successors\n",
    "\tat each step along the shortest path from source to target.\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\t# Get the shortest path from source to target\n",
    "\t\tshortest_path = nx.shortest_path(wiki_game.G, source, target)\n",
    "\texcept nx.NetworkXNoPath:\n",
    "\t\tprint(f\"No path exists between {source} and {target}\")\n",
    "\t\treturn pd.DataFrame()  # Return an empty DataFrame if no path exists\n",
    "\n",
    "\tstats = pd.DataFrame(columns=['source', 'target', 'current_node', 'selection', 'path_length', 'sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality', 'step'])\n",
    "\n",
    "\t# Loop through each node in the shortest path (except the last one)\n",
    "\tfor step, current_node in enumerate(shortest_path[:-2], start=1):\n",
    "\t\tpaths = []\n",
    "\t\t# Get the successors of the current node\n",
    "\t\tfor suc in wiki_game.G.successors(current_node):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tpath_length = len(nx.shortest_path(wiki_game.G, suc, target))\n",
    "\t\t\t\tpaths.append((suc, path_length))\n",
    "\t\t\texcept:\n",
    "\t\t\t\t# paths.append((suc, float('inf')))\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t# Add the successors to the DataFrame\n",
    "\t\tfor suc, path_length in paths:\n",
    "\t\t\tstats.loc[len(stats)] = {\n",
    "\t\t\t\t'source': source,\n",
    "\t\t\t\t'target': target,\n",
    "\t\t\t\t'current_node': current_node,\n",
    "\t\t\t\t'selection': suc,\n",
    "\t\t\t\t'path_length': path_length,\n",
    "\t\t\t\t'sem_sim': semantic_similarity(current_node, suc, wiki_game),\n",
    "\t\t\t\t'pagerank': wiki_game.pagerank[suc],\n",
    "\t\t\t\t'out_degree': wiki_game.G.out_degree(suc),\n",
    "\t\t\t\t'betweenness_centrality': wiki_game.betweenness[suc],\n",
    "\t\t\t\t'step': step\n",
    "\t\t\t}\n",
    "\n",
    "\treturn stats\n",
    "\n",
    "def visualize_path_stats(stats, metrics=['out_degree', 'sem_sim']):\n",
    "\t\"\"\"\n",
    "\tVisualize the distribution of specified metrics at each step of the path using boxplots.\n",
    "\t\"\"\"\n",
    "\n",
    "\tstats.sort_values('path_length', ascending=False, inplace=True)\n",
    "\n",
    "\t# fig, axes = plt.subplots(2,1,figsize=(7, 9), dpi=300)\n",
    "\t# for i, metric in enumerate(metrics):\n",
    "\t# \t# Create a boxplot for the metric with step as the x-axis\n",
    "\t# \t# sns.boxplot(data=stats, x='step', y=metric, ax=axes[i], color='white')\n",
    "\t# \tsns.stripplot(data=stats, x='step', y=metric, ax=axes[i], hue='path_length', palette='RdBu', alpha=0.8, linewidth=0.5, edgecolor='black')\n",
    "\t# \taxes[i].set_title(f'Distribution of {metric} at Each Step')\n",
    "\t# \taxes[i].set_xlabel('Step')\n",
    "\t# \taxes[i].set_ylabel(metric)\n",
    "\t# \tsns.despine()\n",
    "\n",
    "\t# Instead, make a scatterplot for each step\n",
    "\tx = 'sem_sim'\n",
    "\t# y = 'out_degree'\n",
    "\ty = 'betweenness_centrality'\n",
    "\n",
    "\tnrows,ncols = stats['step'].nunique() / 3 + 1, 3\n",
    "\tfig, axes = plt.subplots(int(nrows), int(ncols), figsize=(15, 5*nrows), dpi=300)\n",
    "\taxes = axes.flatten()\n",
    "\tfor step in stats['step'].unique():\n",
    "\t\tstep_stats = stats[stats['step'] == step]\n",
    "\t\tsns.scatterplot(data=step_stats, x=x, y=y, hue='path_length', palette='RdBu', ax=axes[int(step)-1], alpha=0.8, linewidth=0.5, edgecolor='black')\n",
    "\t\t# label the best nodes (min path length)\n",
    "\t\tbest_nodes = step_stats[step_stats['path_length'] == step_stats['path_length'].min()]\n",
    "\t\tfor i, row in best_nodes.iterrows():\n",
    "\t\t\taxes[int(step)-1].text(row[x], row[y], row['selection'], fontsize=8, ha='right', va='bottom')\n",
    "\t\taxes[int(step)-1].set_title(f'Step {int(step)}: {len(step_stats)} nodes')\n",
    "\t\taxes[int(step)-1].set_xlabel(x)\n",
    "\t\taxes[int(step)-1].set_ylabel(y)\n",
    "\t\tsns.despine()\n",
    "\t# Adjust layout\n",
    "\tplt.tight_layout()\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_composite_score(semantic_score, betweenness_score, connectivity_score):\n",
    "    # Normalize input values\n",
    "    norm_semantic = (semantic_score + 1) / 2  # Convert from [-1,1] to [0,1]\n",
    "    norm_betweenness = np.log(betweenness_score + 1)  # Logarithmic scale for betweenness\n",
    "    norm_connectivity = np.log(connectivity_score + 1)  # Logarithmic scale for connectivity\n",
    "    \n",
    "    # Fixed weights\n",
    "    alpha = 0.4  # Semantic similarity weight\n",
    "    beta = 0.4   # Betweenness centrality weight\n",
    "    gamma = 0.2  # Connectivity weight\n",
    "    \n",
    "    # Calculate composite score\n",
    "    composite_score = (alpha * norm_semantic) + (beta * norm_betweenness) + (gamma * norm_connectivity)\n",
    "    return composite_score\n",
    "\n",
    "def semantic_similarity(node1, node2, wiki_game):\n",
    "\t\"\"\"\n",
    "\tCalculate semantic similarity between two nodes using their vector embeddings.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- node1: The first node (article title).\n",
    "\t- node2: The second node (article title).\n",
    "\t- wiki_game: Instance of WikipediaGame class.\n",
    "\n",
    "\tReturns:\n",
    "\t- A float representing the cosine similarity between the two nodes' embeddings.\n",
    "\t\"\"\"\n",
    "\tvec1 = wiki_game.get_vector(node1)\n",
    "\tvec2 = wiki_game.get_vector(node2)\n",
    "\t\n",
    "\tif vec1 is None or vec2 is None:\n",
    "\t\treturn 0.0  # Return 0 if either vector is missing\n",
    "\t\n",
    "\t# Compute cosine similarity\n",
    "\tdot_product = np.dot(vec1, vec2)\n",
    "\tnorm1 = np.linalg.norm(vec1)\n",
    "\tnorm2 = np.linalg.norm(vec2)\n",
    "\t\n",
    "\tif norm1 == 0 or norm2 == 0:\n",
    "\t\treturn 0.0  # Avoid division by zero\n",
    "\t\n",
    "\tsimilarity = dot_product / (norm1 * norm2)\n",
    "\treturn similarity\n",
    "\n",
    "def heuristic_choice(source, target, wiki_game, neighbors):\n",
    "    # List to store neighbors and their scores\n",
    "    scored_neighbors = {}\n",
    "    \n",
    "    # Score each neighbors\n",
    "    for neighbor in neighbors:\n",
    "        semantic_score = semantic_similarity(neighbor, target, wiki_game)\n",
    "        betweenness_score = wiki_game.betweenness[neighbor]\n",
    "        connectivity_score = wiki_game.G.out_degree(neighbor)\n",
    "        \n",
    "        scored_neighbors[neighbor] = compute_composite_score(semantic_score, betweenness_score, connectivity_score)\n",
    "\n",
    "    # Sort the scored neighbors by score in descending order\n",
    "    scored_neighbors = sorted(scored_neighbors.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return scored_neighbors[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_set(wiki_game, num_pairs=1e5):\n",
    "\tn = 0\n",
    "\ti = 0\n",
    "\n",
    "\n",
    "\ttrain_df = pd.DataFrame(columns=['path_length', 'sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality', 'shortest_path'])\n",
    "\n",
    "\twhile n < num_pairs:\n",
    "\t\tsource, target = random.sample(list(wiki_game.article_titles), 2)\n",
    "\t\tif source != target and nx.has_path(wiki_game.G, source, target):\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\t\tstats = generate_path_stats(source, target, wiki_game)\n",
    "\t\t\tif not stats.empty:\n",
    "\t\t\t\tstats.dropna(inplace=True)\n",
    "\t\t\t\tfor step in stats['step'].unique():\n",
    "\t\t\t\t\tstep_stats = stats[stats['step'] == step][['path_length', 'sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality']]\n",
    "\t\t\t\t\tstep_stats['shortest_path'] = step_stats['path_length'] == step_stats['path_length'].min()\n",
    "\t\t\t\t\tif len(step_stats) >= 10:\n",
    "\t\t\t\t\t\t# keep all the rows with the shortest path length, or the top 5 if there are fewer than 5 shortest\n",
    "\t\t\t\t\t\tshortest_path_length = step_stats['path_length'].min()\n",
    "\t\t\t\t\t\tshortest_path_stats = step_stats[step_stats['path_length'] == shortest_path_length]\n",
    "\t\t\t\t\t\t# if len(shortest_path_stats) < 3:\n",
    "\t\t\t\t\t\t# \tshortest_path_stats = step_stats.nlargest(3, 'path_length')\n",
    "\t\t\t\t\t\t# sample the same number of rows from the rest to try to keep the balance\n",
    "\t\t\t\t\t\trest_stats = step_stats[~step_stats.index.isin(shortest_path_stats.index)]\n",
    "\t\t\t\t\t\tif len(rest_stats) > 0:\n",
    "\t\t\t\t\t\t\tsample_size = min(len(shortest_path_stats), len(rest_stats))\n",
    "\t\t\t\t\t\t\trest_stats = rest_stats.sample(n=sample_size, random_state=42)\n",
    "\t\t\t\t\t\t\tstep_stats = pd.concat([shortest_path_stats, rest_stats], ignore_index=True)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tstep_stats = shortest_path_stats\n",
    "\t\t\t\t\ttrain_df = pd.concat([train_df, step_stats], ignore_index=True)\n",
    "\t\t\t\t\tn += len(step_stats)\n",
    "\treturn train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df,test_size=0.2):\n",
    "\tX = train_df[['sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality']]\n",
    "\t# y = train_df['path_length']\n",
    "\ty = train_df['shortest_path'].astype(int)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "\tmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\t# model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\n",
    "\treturn model, X_train, X_test, y_train, y_test\n",
    "\n",
    "def evaluate_model_regression(model, X_test, y_test):\n",
    "\tfrom sklearn.metrics import mean_squared_error, r2_score\n",
    "\ty_pred = model.predict(X_test)\n",
    "\tmse = mean_squared_error(y_test, y_pred)\n",
    "\tr2 = r2_score(y_test, y_pred)\n",
    "\treturn mse, r2\n",
    "\n",
    "def evaluate_model_classification(model, X_test, y_test):\n",
    "\tfrom sklearn.metrics import classification_report, accuracy_score\n",
    "\ty_pred = model.predict(X_test)\n",
    "\taccuracy = accuracy_score(y_test, y_pred)\n",
    "\tprint(accuracy)\n",
    "\treport = classification_report(y_test, y_pred)\n",
    "\tprint(report)\n",
    "\treturn accuracy, report\n",
    "\n",
    "def plot_feature_importances(model, feature_names):\n",
    "\timportances = model.feature_importances_\n",
    "\tindices = np.argsort(importances)[::-1]\n",
    "\n",
    "\tplt.figure(figsize=(4,3),dpi=200)\n",
    "\tplt.title(\"Feature importances\")\n",
    "\tplt.bar(range(len(feature_names)), importances[indices], align=\"center\")\n",
    "\tplt.xticks(range(len(feature_names)), np.array(feature_names)[indices], rotation=90)\n",
    "\tplt.xlim([-1, len(feature_names)])\n",
    "\tsns.despine()\n",
    "\tplt.show()\n",
    "\n",
    "def generate_neighbor_stats(source, target, wiki_game):\n",
    "\t# Just make a small df with the stats from the successors of source\n",
    "\tstats = pd.DataFrame(columns=['selection', 'sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality'])\n",
    "\tneighbors = wiki_game.G.successors(source)\n",
    "\tfor suc in neighbors:\n",
    "\t\tstats.loc[len(stats)] = {\n",
    "\t\t\t'selection': suc,\n",
    "\t\t\t'sem_sim': semantic_similarity(source, suc, wiki_game),\n",
    "\t\t\t'pagerank': wiki_game.pagerank[suc],\n",
    "\t\t\t'out_degree': wiki_game.G.out_degree(suc),\n",
    "\t\t\t'betweenness_centrality': wiki_game.betweenness[suc]\n",
    "\t\t}\n",
    "\treturn stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_choice(source, target, wiki_game, neighbors, model):\n",
    "\n",
    "\t# get stats\n",
    "\tstats = generate_neighbor_stats(source, target, wiki_game)\n",
    "\tX = stats[['sem_sim', 'pagerank', 'out_degree', 'betweenness_centrality']]\n",
    "\tneighbors = [n for n in stats['selection'].values if n in neighbors]\n",
    "\n",
    "\t# predict the path length\n",
    "\ty_pred = model.predict_proba(X)[:, 1]  # Probability of being in the shortest path\n",
    "\tneighbors = [(neighbors[i], y_pred[i]) for i in range(len(neighbors))]\n",
    "\n",
    "\t# sort by predicted path length\n",
    "\tneighbors.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\treturn neighbors[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic with Milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heuristic_milestone_navigation(source, target, wiki_game):\n",
    "\tmin_out_degree = 4\n",
    "\n",
    "\treal_source = source\n",
    "\treal_target = target\n",
    "\n",
    "\tbest_num_phases = -1\n",
    "\tbest_path = []\n",
    "\n",
    "\tfor num_phases in range(0,5):\n",
    "\n",
    "\t\t# print('\\n\\nRunning with', num_phases, 'phases')\n",
    "\n",
    "\t\tvisited = set([real_source])\n",
    "\n",
    "\t\tpath_failed = False\n",
    "\n",
    "\t\t# Select top landmarks based on betweenness centrality\n",
    "\t\tlandmarks = sorted(wiki_game.betweenness.items(), key=lambda x: x[1], reverse=True)[:500]\n",
    "\n",
    "\t\t# Calculate milestones for evenly spaced phases\n",
    "\t\t# For example, with 2 phases we would do max similarity to the source and the one with max similarity to both source and target\n",
    "\t\t# with 3 phases we would do max similarity to the source, max similarity to the target, and max similarity of those two\n",
    "\t\t# etc.\n",
    "\t\tmilestones = []\n",
    "\t\tlandmarks_not_self = [x for x in landmarks if x[0] != real_source and x[0] != real_target]\n",
    "\t\tfor i in range(num_phases):\n",
    "\t\t\t# if i == 0:\n",
    "\t\t\t# \tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], real_source, wiki_game))\n",
    "\t\t\t# elif i == num_phases - 1:\n",
    "\t\t\t# \tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], real_target, wiki_game))\n",
    "\t\t\t# else:\n",
    "\t\t\t# \tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], milestones[i-1][0], wiki_game) + semantic_similarity(x[0], real_target, wiki_game))\n",
    "\t\t\t# milestones.append(milestone[0])\n",
    "\n",
    "\t\t\tif i == num_phases - 1:\n",
    "\t\t\t\tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], real_source, wiki_game))\n",
    "\t\t\telif i == 0:\n",
    "\t\t\t\tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], real_target, wiki_game))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmilestone = max(landmarks_not_self, key=lambda x: semantic_similarity(x[0], milestones[0][0], wiki_game))\n",
    "\t\t\t\n",
    "\t\t\tmilestones.insert(0, milestone[0])\n",
    "\t\t\tlandmarks_not_self.remove(milestone)\n",
    "\n",
    "\t\t# print(\"Milestones:\", milestones)\n",
    "\n",
    "\t\tpath = [real_source]\n",
    "\n",
    "\t\tfor phase in range(1, num_phases + 2):\n",
    "\n",
    "\t\t\tif path_failed:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tif phase > 1:\n",
    "\t\t\t\tsource = milestones[phase - 2]\n",
    "\t\t\telse:\n",
    "\t\t\t\tsource = real_source\n",
    "\n",
    "\t\t\tif phase <= num_phases:\n",
    "\t\t\t\ttarget = milestones[phase - 1]\n",
    "\t\t\telse:\n",
    "\t\t\t\ttarget = real_target\n",
    "\n",
    "\t\t\tif source == target:\n",
    "\t\t\t\t# milestones are the same, just skip\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tcurrent = source\n",
    "\n",
    "\t\t\t# print('\\nPhase', phase, '-', source, '->', target)\n",
    "\n",
    "\t\t\ti = 0\n",
    "\n",
    "\t\t\twhile True:\n",
    "\t\t\t\tif i > 100:\n",
    "\t\t\t\t\t# print('\\nToo many iterations, stopping.')\n",
    "\t\t\t\t\tpath_failed = True\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tvisited.add(current)\n",
    "\n",
    "\t\t\t\tneighbors = list(wiki_game.G.successors(current))\n",
    "\n",
    "\t\t\t\tif target in neighbors:\n",
    "\t\t\t\t\tcurrent = target\n",
    "\t\t\t\t\tvisited.add(current)\n",
    "\t\t\t\t\tpath.append(current)\n",
    "\t\t\t\t\t# print(f' -> {target}!', end='')\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif real_target in neighbors or real_target == current:\n",
    "\t\t\t\t\tcurrent = real_target\n",
    "\t\t\t\t\tpath.append(current)\n",
    "\t\t\t\t\t# print(f' -> {real_target}!', end='')\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif target == current or real_target == current:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tneighbors = [n for n in neighbors if n not in visited]\n",
    "\t\t\t\tif len(neighbors) == 0:\n",
    "\t\t\t\t\t# backtrack\n",
    "\t\t\t\t\tif len(path) <= 1:\n",
    "\t\t\t\t\t\tpath_failed = True\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tcurrent = path[-2]\n",
    "\t\t\t\t\tpath.append(current)\n",
    "\t\t\t\t\ti += 1\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# filter by out_degree\n",
    "\t\t\t\tout_degrees = [wiki_game.G.out_degree(n) for n in neighbors]\n",
    "\t\t\t\tif max(out_degrees) < min_out_degree:\n",
    "\t\t\t\t\tneighbors = [n for n in neighbors if wiki_game.G.out_degree(n) > 0]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tneighbors = [n for n in neighbors if wiki_game.G.out_degree(n) >= min_out_degree]\n",
    "\n",
    "\t\t\t\tif len(neighbors) == 0:\n",
    "\t\t\t\t\t# backtrack\n",
    "\t\t\t\t\tif len(path) <= 1:\n",
    "\t\t\t\t\t\tpath_failed = True\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tcurrent = path[-2]\n",
    "\t\t\t\t\tpath.append(current)\n",
    "\t\t\t\t\ti += 1\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# select neighbor with highest semantic similarity\n",
    "\t\t\t\tsem_sim = -1\n",
    "\t\t\t\tfor n in neighbors:\n",
    "\t\t\t\t\tsim = semantic_similarity(n, target, wiki_game)\n",
    "\t\t\t\t\tif sim > sem_sim:\n",
    "\t\t\t\t\t\tsem_sim = sim\n",
    "\t\t\t\t\t\tbest_neighbor = n\n",
    "\n",
    "\t\t\t\t# if sem_sim == -1:\n",
    "\t\t\t\t# \t# print(f'\\n[Sem Sim == 0]')\n",
    "\t\t\t\t# \tbreak\n",
    "\n",
    "\t\t\t\t# Navigate to the selection\n",
    "\t\t\t\tcurrent = best_neighbor\n",
    "\t\t\t\tpath.append(current)\n",
    "\n",
    "\t\t\t\t# print the selection\n",
    "\t\t\t\t# print(f' -> {current} ({sem_sim:.2f})', end='')\n",
    "\t\t\t\ti += 1\n",
    "\n",
    "\t\t# runs.loc[len(runs)] = {\n",
    "\t\t# \t'source': real_source,\n",
    "\t\t# \t'target': real_target,\n",
    "\t\t# \t'algo_path_length': len(path),\n",
    "\t\t# \t'failed': path_failed,\n",
    "\t\t# \t'num_phases': num_phases,\n",
    "\t\t# \t'real_path_length': len(nx.shortest_path(wiki_game.G, real_source, real_target))\n",
    "\t\t# }\n",
    "\n",
    "\t\tif (path_failed and len(best_path) == 0) or (not path_failed and (len(path) < len(best_path) or len(best_path) == 0)):\n",
    "\t\t\tbest_path = path\n",
    "\t\t\tbest_num_phases = num_phases\n",
    "\t\n",
    "\treturn best_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "\tdef __init__(self, input_dim, hidden_dim=256):  # Larger network\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, hidden_dim),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(hidden_dim, hidden_dim),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(hidden_dim, hidden_dim // 2),  # Additional layer\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(hidden_dim // 2, 1)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Initialize weights properly\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\t\tnn.init.xavier_uniform_(m.weight)\n",
    "\t\t\t\tnn.init.constant_(m.bias, 0)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.fc(x)\n",
    "\n",
    "class WikipediaAgent:\n",
    "\tdef __init__(self, wiki_game, gamma=0.99, lr=1e-3, epsilon_start=1.0):\n",
    "\t\tself.wiki = wiki_game\n",
    "\t\tself.model = DQN(3)\n",
    "\t\tself.target_model = DQN(3)\n",
    "\t\tself.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\t\tself.gamma = gamma\n",
    "\t\tself.epsilon = epsilon_start\n",
    "\t\tself.epsilon_end = 0.01\n",
    "\t\tself.epsilon_decay = 0.975\n",
    "\t\tself.memory = deque(maxlen=10000)\n",
    "\t\tself.batch_size = 64\n",
    "\t\tself.update_target()\n",
    "\t\tself.update_target_counter = 0\n",
    "\t\tself.update_target_freq = 100\n",
    "\n",
    "\tdef update_target(self):\n",
    "\t\tself.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "\tdef decay_epsilon(self):\n",
    "\t\tself.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "\tdef get_state_features(self, title, target):\n",
    "\t\tsem_sim = semantic_similarity(title, target, self.wiki)\n",
    "\t\tout_deg = self.wiki.G.out_degree(title)\n",
    "\t\tbtw = self.wiki.betweenness[title]\n",
    "\t\treturn [sem_sim, out_deg, btw]\n",
    "\n",
    "\tdef choose_action(self, current_title, target_title, candidates=None, use_randomness=True):\n",
    "\t\tneighbors = candidates if candidates is not None else list(self.wiki.G.successors(current_title))\n",
    "\t\tif not neighbors:\n",
    "\t\t\treturn None\n",
    "\t\tif use_randomness and random.random() < self.epsilon:\n",
    "\t\t\treturn random.choice(neighbors)\n",
    "\t\t\n",
    "\t\tscores = []\n",
    "\t\tfor n in neighbors:\n",
    "\t\t\tstate = self.get_state_features(n, target_title)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tq_val = self.model(torch.tensor(state, dtype=torch.float32))\n",
    "\t\t\tscores.append((q_val.item(), n))\n",
    "\t\treturn max(scores, key=lambda x: x[0])[1]\n",
    "\t\n",
    "\tdef compute_step_reward(self, prev_title, new_title, target_title):\n",
    "\t\t\"\"\"Compute immediate reward for a single step\"\"\"\n",
    "\t\t# Immediate success\n",
    "\t\tif new_title == target_title:\n",
    "\t\t\treturn 20  # Big reward for finishing\n",
    "\t\t\n",
    "\t\t# Base step penalty to encourage shorter paths\n",
    "\t\tstep_penalty = -0.5\n",
    "\n",
    "\t\t# Give a big penalty for moving away and a small penalty for staying the same distance\n",
    "\t\tprev_distance = nx.shortest_path_length(self.wiki.G, prev_title, target_title)\n",
    "\t\tnew_distance = nx.shortest_path_length(self.wiki.G, new_title, target_title)\n",
    "\n",
    "\t\tif new_distance < prev_distance:\n",
    "\t\t\treturn 2 + step_penalty\n",
    "\t\telif new_distance == prev_distance:\n",
    "\t\t\treturn -0.2 + step_penalty\n",
    "\t\telse:\n",
    "\t\t\treturn -1 + step_penalty\n",
    "\n",
    "\tdef compute_step_reward(self, prev_title, new_title, target_title):\n",
    "\t\t\"\"\"Compute immediate reward for a single step with better shaping\"\"\"\n",
    "\t\t# Immediate success\n",
    "\t\tif new_title == target_title:\n",
    "\t\t\treturn 10  # Still good but not as extreme\n",
    "\t\t\n",
    "\t\t# Calculate distances\n",
    "\t\tprev_distance = nx.shortest_path_length(self.wiki.G, prev_title, target_title)\n",
    "\t\tnew_distance = nx.shortest_path_length(self.wiki.G, new_title, target_title)\n",
    "\t\t\n",
    "\t\t# Reward based on distance change - more pronounced gradient\n",
    "\t\tif new_distance < prev_distance:\n",
    "\t\t\treturn 5\n",
    "\t\telif new_distance == prev_distance:\n",
    "\t\t\treturn -0.5\n",
    "\t\telse:\n",
    "\t\t\treturn -2\n",
    "\n",
    "\n",
    "\tdef store_episode(self, trajectory):\n",
    "\t\t\"\"\"Store entire episode for Monte Carlo learning\"\"\"\n",
    "\t\tif trajectory:  # Only store if we have actual transitions\n",
    "\t\t\tself.memory.append(trajectory)\n",
    "\n",
    "\tdef train_step_td(self):\n",
    "\t\t\"\"\"Train using TD learning instead of Monte Carlo returns\"\"\"\n",
    "\t\tif len(self.memory) < self.batch_size:\n",
    "\t\t\treturn 0\n",
    "\t\t\n",
    "\t\t# Flatten trajectories to get individual transitions\n",
    "\t\tall_transitions = [t for trajectory in self.memory for t in trajectory]\n",
    "\t\tif len(all_transitions) < self.batch_size:\n",
    "\t\t\treturn 0\n",
    "\t\t\t\n",
    "\t\t# Sample batch of transitions\n",
    "\t\tbatch = random.sample(all_transitions, self.batch_size)\n",
    "\t\tstates, action_feats, rewards, next_states, dones = zip(*batch)\n",
    "\t\t\n",
    "\t\t# Convert to tensors\n",
    "\t\tstates_tensor = torch.tensor(np.stack(action_feats), dtype=torch.float32)\n",
    "\t\trewards_tensor = torch.tensor(rewards, dtype=torch.float32)\n",
    "\t\tnext_states_tensor = torch.tensor(np.stack(next_states), dtype=torch.float32)\n",
    "\t\tdones_tensor = torch.tensor(dones, dtype=torch.float32)\n",
    "\t\t\n",
    "\t\t# Get current Q values\n",
    "\t\tcurrent_q = self.model(states_tensor).squeeze()\n",
    "\t\t\n",
    "\t\t# Get next Q values from target network\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnext_q = self.target_model(next_states_tensor).squeeze()\n",
    "\t\t\n",
    "\t\t# Compute target Q values\n",
    "\t\ttarget_q = rewards_tensor + (1 - dones_tensor) * self.gamma * next_q\n",
    "\t\t\n",
    "\t\t# Compute loss\n",
    "\t\tloss = nn.MSELoss()(current_q, target_q)\n",
    "\t\t\n",
    "\t\t# Optimize\n",
    "\t\tself.optimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\tself.optimizer.step()\n",
    "\t\t\n",
    "\t\t# Update target network more frequently\n",
    "\t\tself.update_target_counter += 1\n",
    "\t\tif self.update_target_counter >= 10:  # More frequent updates (was 100)\n",
    "\t\t\tself.update_target()\n",
    "\t\t\tself.update_target_counter = 0\n",
    "\t\t\n",
    "\t\treturn loss.item()\n",
    "\n",
    "\tdef train_step_monte_carlo(self):\n",
    "\t\t\"\"\"Train using Monte Carlo returns instead of TD learning\"\"\"\n",
    "\t\tif len(self.memory) < 10:  # Need at least some episodes\n",
    "\t\t\treturn 0\n",
    "\t\t\n",
    "\t\t# Sample a batch of episodes\n",
    "\t\tbatch_episodes = random.sample(self.memory, min(self.batch_size, len(self.memory)))\n",
    "\t\t\n",
    "\t\tall_losses = []\n",
    "\t\t\n",
    "\t\tfor episode in batch_episodes:\n",
    "\t\t\tif not episode:  # Skip empty episodes\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\tstates, action_feats, rewards, next_states, dones = zip(*episode)\n",
    "\t\t\t\n",
    "\t\t\t# Calculate returns for each step in the episode\n",
    "\t\t\treturns = []\n",
    "\t\t\tG = 0\n",
    "\t\t\tfor r in reversed(rewards):\n",
    "\t\t\t\tG = r + self.gamma * G\n",
    "\t\t\t\treturns.insert(0, G)\n",
    "\t\t\t\n",
    "\t\t\t# Convert to tensors\n",
    "\t\t\tstates = torch.tensor(np.stack(action_feats), dtype=torch.float32)  # We use action features as states\n",
    "\t\t\treturns = torch.tensor(returns, dtype=torch.float32)\n",
    "\t\t\t\n",
    "\t\t\t# Get predicted values\n",
    "\t\t\tpredicted_values = self.model(states).squeeze()\n",
    "\t\t\t\n",
    "\t\t\t# Calculate loss\n",
    "\t\t\tloss = nn.MSELoss()(predicted_values, returns)\n",
    "\t\t\t\n",
    "\t\t\t# Optimize\n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\t\t\n",
    "\t\t\tall_losses.append(loss.item())\n",
    "\t\t\n",
    "\t\t# Update target network periodically\n",
    "\t\tself.update_target_counter += 1\n",
    "\t\tif self.update_target_counter >= self.update_target_freq:\n",
    "\t\t\tself.update_target()\n",
    "\t\t\tself.update_target_counter = 0\n",
    "\t\t\n",
    "\t\treturn np.mean(all_losses) if all_losses else 0\n",
    "\n",
    "\tdef play_episode(self, start_title, target_title, max_steps=20, max_attempts=3):\n",
    "\t\t\"\"\"Play an episode and store the trajectory for Monte Carlo learning\"\"\"\n",
    "\t\tfor attempt in range(max_attempts):\n",
    "\t\t\tcurrent = start_title\n",
    "\t\t\ttrajectory = []\n",
    "\t\t\tvisited = set([current])\n",
    "\t\t\t\n",
    "\t\t\tfor step in range(max_steps):\n",
    "\t\t\t\tstate = self.get_state_features(current, target_title)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Get available actions (exclude already visited)\n",
    "\t\t\t\tneighbors = list(self.wiki.G.successors(current))\n",
    "\t\t\t\tunvisited = [n for n in neighbors if n not in visited]\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Handle target if available\n",
    "\t\t\t\tif target_title in unvisited:\n",
    "\t\t\t\t\taction = target_title\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif not unvisited:\n",
    "\t\t\t\t\t\t# Dead end - make this attempt invalid\n",
    "\t\t\t\t\t\ttrajectory = []\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\taction = self.choose_action(current, target_title, candidates=unvisited)\n",
    "\t\t\t\t\tif action is None or not nx.has_path(self.wiki.G, action, target_title):\n",
    "\t\t\t\t\t\ttrajectory = []\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\tvisited.add(action)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Get next state features\n",
    "\t\t\t\taction_feat = self.get_state_features(action, target_title)\n",
    "\t\t\t\treward = self.compute_step_reward(current, action, target_title)\n",
    "\t\t\t\tnext_state = self.get_state_features(action, target_title)\n",
    "\t\t\t\tdone = action == target_title\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Store transition\n",
    "\t\t\t\ttrajectory.append((state, action_feat, reward, next_state, done))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Update current state\n",
    "\t\t\t\tcurrent = action\n",
    "\t\t\t\t\n",
    "\t\t\t\tif done:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\t# If we found a valid path, store it and exit retry loop\n",
    "\t\t\tif trajectory and (trajectory[-1][4] or len(trajectory) >= 3):\n",
    "\t\t\t\t# Only store if we reached the target or made at least 3 steps\n",
    "\t\t\t\tself.store_episode(trajectory)\n",
    "\t\t\t\t# self.train_step_monte_carlo()\n",
    "\t\t\t\tself.train_step_td()\n",
    "\t\t\t\tself.decay_epsilon()\n",
    "\t\t\t\treturn trajectory\n",
    "\t\t\t\t\n",
    "\t\t# If all attempts failed, return empty trajectory\n",
    "\t\treturn []\n",
    "\n",
    "\tdef validate_path_exists(self, start, target):\n",
    "\t\t\"\"\"Check if there's a path between start and target\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\t# Just check if a path exists, not the actual path\n",
    "\t\t\tprint(f\"Checking path from {start} to {target}\")\n",
    "\t\t\tpath_exists = nx.has_path(self.wiki.G, start, target)\n",
    "\t\t\treturn path_exists\n",
    "\t\texcept (nx.NetworkXError, nx.NodeNotFound):\n",
    "\t\t\treturn False\n",
    "\t\n",
    "\tdef evaluate(self, start_title, target_title, max_steps=20, verbose=False):\n",
    "\t\t\"\"\"Run an episode for evaluation with backtracking for dead ends\"\"\"\n",
    "\t\t# First check if a path exists\n",
    "\t\tif not nx.has_path(self.wiki.G, start_title, target_title):\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"No path exists from {start_title} to {target_title}\")\n",
    "\t\t\treturn [], 0\n",
    "\t\t\t\t\n",
    "\t\tcurrent = start_title\n",
    "\t\tpath = [current]\n",
    "\t\ttotal_reward = 0\n",
    "\t\tvisited = set([current])\n",
    "\t\t\n",
    "\t\t# Stack to keep track of our exploration path for backtracking\n",
    "\t\texploration_stack = [(current, list(self.wiki.G.successors(current)))]\n",
    "\t\t\n",
    "\t\tstep_count = 0\n",
    "\t\twhile exploration_stack and step_count < max_steps:\n",
    "\t\t\tcurrent, neighbors = exploration_stack[-1]\n",
    "\t\t\t\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"Step {step_count}: At {current}, stack depth: {len(exploration_stack)}\")\n",
    "\t\t\t\n",
    "\t\t\t# Filter neighbors to those not visited\n",
    "\t\t\tunvisited = [n for n in neighbors if n not in visited]\n",
    "\t\t\t\n",
    "\t\t\t# Direct path to target if available\n",
    "\t\t\tif target_title in unvisited:\n",
    "\t\t\t\tpath.append(target_title)\n",
    "\t\t\t\treward = self.compute_step_reward(current, target_title, target_title)\n",
    "\t\t\t\ttotal_reward += reward\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint(f\"  Found target! Reward: {reward}\")\n",
    "\t\t\t\treturn path, total_reward\n",
    "\t\t\t\n",
    "\t\t\tif not unvisited:\n",
    "\t\t\t\t# Dead end - backtrack\n",
    "\t\t\t\texploration_stack.pop()\n",
    "\t\t\t\tif exploration_stack:\n",
    "\t\t\t\t\t# Move back to previous node\n",
    "\t\t\t\t\tprev_node = exploration_stack[-1][0]\n",
    "\t\t\t\t\tif verbose:\n",
    "\t\t\t\t\t\tprint(f\"  Dead end at {current}, backtracking to {prev_node}\")\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Only add backtracking nodes to path if they're not already the last node\n",
    "\t\t\t\t\tif path[-1] != prev_node:\n",
    "\t\t\t\t\t\tpath.append(prev_node)\n",
    "\t\t\t\t\t\t# Small penalty for backtracking\n",
    "\t\t\t\t\t\ttotal_reward -= 0.3\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\t# Choose best action\n",
    "\t\t\tscores = []\n",
    "\t\t\tfor n in unvisited:\n",
    "\t\t\t\tstate = self.get_state_features(n, target_title)\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\tq_val = self.model(torch.tensor(state, dtype=torch.float32))\n",
    "\t\t\t\tscores.append((q_val.item(), n))\n",
    "\t\t\t\n",
    "\t\t\tscores = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\t\t\taction = scores[0][1]\n",
    "\t\t\ti = 1\n",
    "\t\t\twhile not nx.has_path(self.wiki.G, action, target_title):\n",
    "\t\t\t\t# give a penalty for choosing a dead end\n",
    "\t\t\t\ttotal_reward -= 4\n",
    "\t\t\t\t# choose the next best action\n",
    "\t\t\t\taction = scores[i][1]\n",
    "\t\t\t\ti += 1\n",
    "\t\t\t\tif i >= len(scores):\n",
    "\t\t\t\t\t# If we run out of options, we're in a dead end\n",
    "\t\t\t\t\treturn path, total_reward\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t# Remove this action from current neighbors\n",
    "\t\t\texploration_stack[-1] = (current, [n for n in neighbors if n != action])\n",
    "\t\t\t\n",
    "\t\t\t# Mark as visited and proceed\n",
    "\t\t\tvisited.add(action)\n",
    "\t\t\treward = self.compute_step_reward(current, action, target_title)\n",
    "\t\t\ttotal_reward += reward\n",
    "\t\t\t\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"  Selected {action} with reward {reward:.4f}\")\n",
    "\t\t\t\n",
    "\t\t\tcurrent = action\n",
    "\t\t\tpath.append(current)\n",
    "\t\t\t\n",
    "\t\t\t# Add new node to exploration stack\n",
    "\t\t\texploration_stack.append((current, list(self.wiki.G.successors(current))))\n",
    "\t\t\t\n",
    "\t\t\tif current == target_title:\n",
    "\t\t\t\tif verbose:\n",
    "\t\t\t\t\tprint(\"  Reached target!\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\tstep_count += 1\n",
    "\t\t\n",
    "\t\tif verbose and current != target_title:\n",
    "\t\t\tprint(f\"  Failed to reach target after {len(path)} steps\")\n",
    "\t\t\t\t\t\n",
    "\t\treturn path, total_reward\n",
    "\n",
    "\tdef train(self, episodes, start_pool, target_pool, max_steps=20):\n",
    "\t\t\"\"\"Train the agent for a specified number of episodes\"\"\"\n",
    "\t\ttraining_history = []\n",
    "\t\tsuccessful_episodes = 0\n",
    "\t\t\n",
    "\t\tfor episode in range(episodes):\n",
    "\t\t\t# Sample start and target\n",
    "\t\t\tstart = random.choice(start_pool)\n",
    "\t\t\ttarget = random.choice(target_pool)\n",
    "\t\t\t\n",
    "\t\t\t# Make sure start and target are different and a path exists\n",
    "\t\t\tattempts = 0\n",
    "\t\t\twhile (start == target or not self.validate_path_exists(start, target)) and attempts < 10:\n",
    "\t\t\t\ttarget = random.choice(target_pool)\n",
    "\t\t\t\tattempts += 1\n",
    "\t\t\t\t\n",
    "\t\t\tif attempts >= 10:\n",
    "\t\t\t\t# If we can't find a valid pair after multiple attempts, skip this episode\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\t# Play episode\n",
    "\t\t\ttrajectory = self.play_episode(start, target, max_steps)\n",
    "\t\t\t\n",
    "\t\t\t# Calculate stats\n",
    "\t\t\tpath_length = len(trajectory)\n",
    "\t\t\ttotal_reward = sum(t[2] for t in trajectory) if trajectory else 0\n",
    "\t\t\tsuccess = trajectory and trajectory[-1][4]  # Check if the last step reached the target\n",
    "\t\t\t\n",
    "\t\t\tif success:\n",
    "\t\t\t\tsuccessful_episodes += 1\n",
    "\t\t\t\n",
    "\t\t\ttraining_history.append({\n",
    "\t\t\t\t'episode': episode,\n",
    "\t\t\t\t'path_length': path_length,\n",
    "\t\t\t\t'total_reward': total_reward,\n",
    "\t\t\t\t'success': success,\n",
    "\t\t\t\t'epsilon': self.epsilon\n",
    "\t\t\t})\n",
    "\t\t\t\n",
    "\t\t\t# Optional: Print progress\n",
    "\t\t\tif episode % 10 == 0:\n",
    "\t\t\t\tsuccess_rate = successful_episodes / (episode + 1) * 100 if episode > 0 else 0\n",
    "\t\t\t\tprint(f\"Episode {episode}, Success: {success}, Path Length: {path_length}, \"\n",
    "\t\t\t\t\t  f\"Reward: {total_reward:.2f}, Success Rate: {success_rate:.1f}%\")\n",
    "\t\t\n",
    "\t\treturn training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl(epochs=1000, agent=None):\n",
    "\tif agent is None:\n",
    "\t\t# Initialize the agent\n",
    "\t\tagent = WikipediaAgent(wiki_game)\n",
    "\t\n",
    "\t# Train for n epochs\n",
    "\tfor epoch in tqdm(range(epochs)):\n",
    "\t\tstart, target = random.sample(list(wiki_game.article_titles), 2)\n",
    "\t\tif nx.has_path(wiki_game.G, start, target):\n",
    "\t\t\tagent.play_episode(start, target)\n",
    "\t\tif epoch % 50 == 0:\n",
    "\t\t\tagent.update_target()\n",
    "\n",
    "\treturn agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_choice(source, target, wiki_game, neighbors, agent):\n",
    "    choice = agent.choose_action(source, target, candidates=neighbors, use_randomness=False)\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch.save(agent.model.state_dict(), \"wiki_dqn.4.22.25.pth\")\n",
    "\n",
    "# agent = WikipediaAgent(wiki_game)\n",
    "# agent.model.load_state_dict(torch.load(\"wiki_dqn.4.22.25.pth\"))\n",
    "# agent.model.eval()  # set to inference mode\n",
    "\n",
    "# navigate_reinforcement_learning('Apple', 'Moon', wiki_game, agent=agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def navigate(source, target, wiki_game, method, max_length=100, agent=None, model=None):\n",
    "\n",
    "\t# methods\n",
    "\tmethods = ['heuristic','ml','rl']\n",
    "\tif method not in methods:\n",
    "\t\traise ValueError(f\"Method must be one of {methods}\")\n",
    "\tif method == 'ml':\n",
    "\t\tassert model is not None, \"Model must be provided for ML method\"\n",
    "\tif method == 'rl':\n",
    "\t\tassert agent is not None, \"Agent must be provided for RL method\"\n",
    "\n",
    "\t# Start navigating\n",
    "\tvisited = set()\n",
    "\tcurrent = source\n",
    "\tpath = [current]\n",
    "\tvisited.add(current)\n",
    "\n",
    "\ti = 0\n",
    "\twhile i < max_length:\n",
    "\n",
    "\t\tneighbors = list(wiki_game.G.successors(current))\n",
    "\n",
    "\t\tneighbors = [n for n in neighbors if n not in visited]\n",
    "\t\t\n",
    "\t\t# check if target is in neighbors\n",
    "\t\tif target in neighbors:\n",
    "\t\t\tpath.append(target)\n",
    "\t\t\treturn path\n",
    "\t\t\n",
    "\t\t# backtrack if no unvisited neighbors\n",
    "\t\tif len(neighbors) == 0:\n",
    "\t\t\tif len(path) <= 1:\n",
    "\t\t\t\treturn path\n",
    "\t\t\t# Backtrack\n",
    "\t\t\tcurrent = path[-2]\n",
    "\t\t\tpath.append(current)\n",
    "\t\t\ti += 1\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t# make a choice based on the method\n",
    "\t\tif method == 'heuristic':\n",
    "\t\t\tchoice = heuristic_choice(current, target, wiki_game, neighbors)\n",
    "\t\telif method == 'ml':\n",
    "\t\t\tchoice = ml_choice(current, target, wiki_game, neighbors, model)\n",
    "\t\telif method == 'rl':\n",
    "\t\t\tchoice = rl_choice(current, target, wiki_game, neighbors, agent)\n",
    "\t\t\n",
    "\t\t# check if choice is valid\n",
    "\t\tassert choice in neighbors, f\"Choice {choice} is not a neighbor of {current}\"\n",
    "\n",
    "\t\t# add choice to path\n",
    "\t\tpath.append(choice)\n",
    "\t\tvisited.add(choice)\n",
    "\t\tcurrent = choice\n",
    "\t\t\n",
    "\t\ti += 1\n",
    "\t\n",
    "\treturn path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate('Apple', 'Moon', wiki_game, method='heuristic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate('Apple', 'Moon', wiki_game, method='ml', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate('Apple', 'Moon', wiki_game, method='rl', agent=agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classifier\n",
    "# train_df = make_training_set(wiki_game, num_pairs=10000)\n",
    "\n",
    "# train_df['out_degree'] = train_df['out_degree'].astype(int)\n",
    "# train_df['sem_sim'] = train_df['sem_sim'].astype(float)\n",
    "\n",
    "# # Split the data and train the model\n",
    "# model, X_train, X_test, y_train, y_test = train_model(train_df)\n",
    "\n",
    "# # Report performance\n",
    "# acc, report = evaluate_model_classification(model, X_test, y_test)\n",
    "# plot_feature_importances(model, X_train.columns)\n",
    "\n",
    "# # Save the random forest model\n",
    "import joblib\n",
    "# joblib.dump(model, 'random_forest_model.4.28.25.pkl')\n",
    "\n",
    "model = joblib.load('random_forest_model.4.28.25.pkl')\n",
    "# navigate('Apple', 'Moon', wiki_game, method='ml', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = WikipediaAgent(wiki_game)\n",
    "agent.model.load_state_dict(torch.load(\"wiki_dqn.4.22.25.pth\"))\n",
    "\n",
    "# for i in range(5):\n",
    "# \tagent = train_rl(epochs=100, agent=agent)\n",
    "# \ttorch.save(agent.model.state_dict(), \"wiki_dqn.4.22.25.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [12:21<00:00, 30.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>My path length</th>\n",
       "      <th>Heuristic path</th>\n",
       "      <th>Heuristic path length</th>\n",
       "      <th>Heuristic time</th>\n",
       "      <th>ML path</th>\n",
       "      <th>ML path length</th>\n",
       "      <th>ML time</th>\n",
       "      <th>RL path</th>\n",
       "      <th>RL path length</th>\n",
       "      <th>RL time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Clauset</td>\n",
       "      <td>Paul ErdÅ‘s</td>\n",
       "      <td>3</td>\n",
       "      <td>[Aaron Clauset, Physics, Albert Einstein, Unit...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.253698</td>\n",
       "      <td>[Aaron Clauset, Computer science, List of word...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.027043</td>\n",
       "      <td>[Aaron Clauset, Physics, List of Jupiter's moo...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.434564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linux</td>\n",
       "      <td>Fred Rogers</td>\n",
       "      <td>11</td>\n",
       "      <td>[Linux, List of Linux distributions, Poland, U...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.470259</td>\n",
       "      <td>[Linux, Linux Mint, Advanced Packaging Tool, D...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.388906</td>\n",
       "      <td>[Linux, List of Linux distributions, Poland, U...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.977975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wasabi</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>22</td>\n",
       "      <td>[Wasabi, Japan, United States, Ronald Reagan, ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.727856</td>\n",
       "      <td>[Wasabi, New Zealand, Unitary state, Niger, Tu...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.835197</td>\n",
       "      <td>[Wasabi, Japan, United States, Ronald Reagan, ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.508489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red (Taylor Swift album)</td>\n",
       "      <td>Ulysses (novel)</td>\n",
       "      <td>7</td>\n",
       "      <td>[Red (Taylor Swift album), Taylor Swift, Speak...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.662778</td>\n",
       "      <td>[Red (Taylor Swift album), Americans, United S...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.166886</td>\n",
       "      <td>[Red (Taylor Swift album), Taylor Swift, YouTu...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>33.562705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batman</td>\n",
       "      <td>FC Bayern Munich</td>\n",
       "      <td>5</td>\n",
       "      <td>[Batman, DC Extended Universe, DC Comics, Unit...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.064375</td>\n",
       "      <td>[Batman, Batman v Superman: Dawn of Justice, D...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.481047</td>\n",
       "      <td>[Batman, DC Extended Universe, DC Comics, Unit...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.080184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Entropy</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>9</td>\n",
       "      <td>[Entropy, Thermodynamic entropy, Earth, United...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.836018</td>\n",
       "      <td>[Entropy, Information entropy, Thermodynamic e...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.675905</td>\n",
       "      <td>[Entropy, Thermodynamic entropy, Earth, United...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>28.869218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Tom and Jerry</td>\n",
       "      <td>13</td>\n",
       "      <td>[Brooklyn, New York City, United States, Ronal...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.602427</td>\n",
       "      <td>[Brooklyn, New York City, Morgan Stanley, Unit...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.174529</td>\n",
       "      <td>[Brooklyn, New York City, United States, Ronal...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29.712728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FrÃ©dÃ©ric Chopin</td>\n",
       "      <td>Ganymede (moon)</td>\n",
       "      <td>7</td>\n",
       "      <td>[FrÃ©dÃ©ric Chopin, France, ISO 4217, United Sta...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.453630</td>\n",
       "      <td>[FrÃ©dÃ©ric Chopin, Poland, Christianity, 21st c...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.588700</td>\n",
       "      <td>[FrÃ©dÃ©ric Chopin, France, ISO 4217, Country co...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.389576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rockhole frog</td>\n",
       "      <td>Alps</td>\n",
       "      <td>5</td>\n",
       "      <td>[Rockhole frog, Australia, United States, Rona...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.270896</td>\n",
       "      <td>[Rockhole frog, Australia, United States, Fran...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.068968</td>\n",
       "      <td>[Rockhole frog, Australia, United States, Rona...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.244258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Peach (color)</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>5</td>\n",
       "      <td>[Peach (color), China, France, Belgium, German...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.080619</td>\n",
       "      <td>[Peach (color), English language, United State...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.892816</td>\n",
       "      <td>[Peach (color), English language, United State...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.310228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Fascism</td>\n",
       "      <td>4</td>\n",
       "      <td>[Donald Trump, Bernie Sanders, Time Person of ...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.312373</td>\n",
       "      <td>[Donald Trump, Australia, United States, Franc...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.298799</td>\n",
       "      <td>[Donald Trump, Bernie Sanders, Ronald Reagan, ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.071773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>Equilateral triangle</td>\n",
       "      <td>6</td>\n",
       "      <td>[Boston Red Sox, 1912, 1980, 2008, 2006, 2021,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.862048</td>\n",
       "      <td>[Boston Red Sox, Boston, United States, France...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.804951</td>\n",
       "      <td>[Boston Red Sox, 1912, 1980, 2008, 2006, 2021,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.457788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Infinite Jest</td>\n",
       "      <td>University of Colorado Boulder</td>\n",
       "      <td>11</td>\n",
       "      <td>[Infinite Jest, David Foster Wallace, American...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.562252</td>\n",
       "      <td>[Infinite Jest, David Foster Wallace, Ithaca, ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.746690</td>\n",
       "      <td>[Infinite Jest, David Foster Wallace, American...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.997787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>War of 1812</td>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>8</td>\n",
       "      <td>[War of 1812, United States, Ronald Reagan, Ch...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.500908</td>\n",
       "      <td>[War of 1812, France, 1953, Pierce Brosnan, Un...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.906122</td>\n",
       "      <td>[War of 1812, United States, Ronald Reagan, Ch...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.522481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bo Burnham</td>\n",
       "      <td>Cosmic microwave background radiation</td>\n",
       "      <td>7</td>\n",
       "      <td>[Bo Burnham, Comedy Central, United States, Ro...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.570114</td>\n",
       "      <td>[Bo Burnham, MTV, United States, France, 1953,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.009554</td>\n",
       "      <td>[Bo Burnham, Comedy Central, United States, Ro...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.384012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Orangutan</td>\n",
       "      <td>The Lord of the Rings</td>\n",
       "      <td>7</td>\n",
       "      <td>[Orangutan, Singapore, March, 2019, 1980, 2008...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.689521</td>\n",
       "      <td>[Orangutan, Singapore, World War I, United Sta...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.782238</td>\n",
       "      <td>[Orangutan, Singapore, March, 2019, 1980, 2008...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>23.049131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Britpop</td>\n",
       "      <td>Daniel Dennett</td>\n",
       "      <td>8</td>\n",
       "      <td>[Britpop, United States, Ronald Reagan, Chicag...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.848432</td>\n",
       "      <td>[Britpop, United States, France, 1953, Pierce ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.909298</td>\n",
       "      <td>[Britpop, United States, Ronald Reagan, Chicag...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.620080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Quantum immortality</td>\n",
       "      <td>Saul Goodman</td>\n",
       "      <td>14</td>\n",
       "      <td>[Quantum immortality, Copenhagen interpretatio...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.431880</td>\n",
       "      <td>[Quantum immortality, SchrÃ¶dinger's cat, Erwin...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.156051</td>\n",
       "      <td>[Quantum immortality, Copenhagen interpretatio...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.397321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>French invasion of Russia</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>6</td>\n",
       "      <td>[French invasion of Russia, France, ISO 4217, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.351118</td>\n",
       "      <td>[French invasion of Russia, Europe, Middle Age...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.898292</td>\n",
       "      <td>[French invasion of Russia, France, ISO 4217, ...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.650933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Medieval philosophy</td>\n",
       "      <td>Vitamin D</td>\n",
       "      <td>8</td>\n",
       "      <td>[Medieval philosophy, France, ISO 4217, Countr...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.846550</td>\n",
       "      <td>[Medieval philosophy, France, 1953, Pierce Bro...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.258053</td>\n",
       "      <td>[Medieval philosophy, France, ISO 4217, Countr...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.865095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Catfish</td>\n",
       "      <td>6</td>\n",
       "      <td>[Cat, Egypt, Christianity, 20th century, 1980,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.473007</td>\n",
       "      <td>[Cat, Human, United States, France, 1953, Pier...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.488573</td>\n",
       "      <td>[Cat, Egypt, Christianity, 20th century, 1980,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.358455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Game Boy Color</td>\n",
       "      <td>5</td>\n",
       "      <td>[Vampire, Europe, Russia, United States, Ronal...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.423110</td>\n",
       "      <td>[Vampire, Buffy the Vampire Slayer, United Sta...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.206432</td>\n",
       "      <td>[Vampire, Europe, Russia, United States, Ronal...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.705460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Magna Carta</td>\n",
       "      <td>DNA</td>\n",
       "      <td>4</td>\n",
       "      <td>[Magna Carta, England, DNA]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>[Magna Carta, BBC, June 27, United States, Fra...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.980595</td>\n",
       "      <td>[Magna Carta, England, DNA]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>Encyclopedia</td>\n",
       "      <td>6</td>\n",
       "      <td>[Jeopardy!, United States, Ronald Reagan, Chic...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.767781</td>\n",
       "      <td>[Jeopardy!, United States, France, 1953, Pierc...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.677324</td>\n",
       "      <td>[Jeopardy!, United States, Ronald Reagan, Chic...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.835668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Source                                 Target  \\\n",
       "0               Aaron Clauset                             Paul ErdÅ‘s   \n",
       "1                       Linux                            Fred Rogers   \n",
       "2                      Wasabi                             Adobe Inc.   \n",
       "3    Red (Taylor Swift album)                        Ulysses (novel)   \n",
       "4                      Batman                       FC Bayern Munich   \n",
       "5                     Entropy                           Tuberculosis   \n",
       "6                    Brooklyn                          Tom and Jerry   \n",
       "7             FrÃ©dÃ©ric Chopin                        Ganymede (moon)   \n",
       "8               Rockhole frog                                   Alps   \n",
       "9               Peach (color)                                  Tokyo   \n",
       "10               Donald Trump                                Fascism   \n",
       "11             Boston Red Sox                   Equilateral triangle   \n",
       "12              Infinite Jest         University of Colorado Boulder   \n",
       "13                War of 1812                             Pink Floyd   \n",
       "14                 Bo Burnham  Cosmic microwave background radiation   \n",
       "15                  Orangutan                  The Lord of the Rings   \n",
       "16                    Britpop                         Daniel Dennett   \n",
       "17        Quantum immortality                           Saul Goodman   \n",
       "18  French invasion of Russia                             Gymnastics   \n",
       "19        Medieval philosophy                              Vitamin D   \n",
       "20                        Cat                                Catfish   \n",
       "21                    Vampire                         Game Boy Color   \n",
       "22                Magna Carta                                    DNA   \n",
       "23                  Jeopardy!                           Encyclopedia   \n",
       "\n",
       "    My path length                                     Heuristic path  \\\n",
       "0                3  [Aaron Clauset, Physics, Albert Einstein, Unit...   \n",
       "1               11  [Linux, List of Linux distributions, Poland, U...   \n",
       "2               22  [Wasabi, Japan, United States, Ronald Reagan, ...   \n",
       "3                7  [Red (Taylor Swift album), Taylor Swift, Speak...   \n",
       "4                5  [Batman, DC Extended Universe, DC Comics, Unit...   \n",
       "5                9  [Entropy, Thermodynamic entropy, Earth, United...   \n",
       "6               13  [Brooklyn, New York City, United States, Ronal...   \n",
       "7                7  [FrÃ©dÃ©ric Chopin, France, ISO 4217, United Sta...   \n",
       "8                5  [Rockhole frog, Australia, United States, Rona...   \n",
       "9                5  [Peach (color), China, France, Belgium, German...   \n",
       "10               4  [Donald Trump, Bernie Sanders, Time Person of ...   \n",
       "11               6  [Boston Red Sox, 1912, 1980, 2008, 2006, 2021,...   \n",
       "12              11  [Infinite Jest, David Foster Wallace, American...   \n",
       "13               8  [War of 1812, United States, Ronald Reagan, Ch...   \n",
       "14               7  [Bo Burnham, Comedy Central, United States, Ro...   \n",
       "15               7  [Orangutan, Singapore, March, 2019, 1980, 2008...   \n",
       "16               8  [Britpop, United States, Ronald Reagan, Chicag...   \n",
       "17              14  [Quantum immortality, Copenhagen interpretatio...   \n",
       "18               6  [French invasion of Russia, France, ISO 4217, ...   \n",
       "19               8  [Medieval philosophy, France, ISO 4217, Countr...   \n",
       "20               6  [Cat, Egypt, Christianity, 20th century, 1980,...   \n",
       "21               5  [Vampire, Europe, Russia, United States, Ronal...   \n",
       "22               4                        [Magna Carta, England, DNA]   \n",
       "23               6  [Jeopardy!, United States, Ronald Reagan, Chic...   \n",
       "\n",
       "    Heuristic path length  Heuristic time  \\\n",
       "0                    36.0        1.253698   \n",
       "1                    51.0        1.470259   \n",
       "2                    51.0        1.727856   \n",
       "3                    51.0        1.662778   \n",
       "4                     7.0        0.064375   \n",
       "5                    51.0        1.836018   \n",
       "6                    51.0        1.602427   \n",
       "7                    15.0        0.453630   \n",
       "8                    11.0        0.270896   \n",
       "9                     8.0        0.080619   \n",
       "10                   32.0        1.312373   \n",
       "11                   51.0        1.862048   \n",
       "12                   51.0        1.562252   \n",
       "13                   26.0        0.500908   \n",
       "14                   51.0        1.570114   \n",
       "15                   51.0        1.689521   \n",
       "16                   51.0        1.848432   \n",
       "17                   51.0        1.431880   \n",
       "18                   13.0        0.351118   \n",
       "19                   51.0        1.846550   \n",
       "20                   51.0        1.473007   \n",
       "21                   51.0        1.423110   \n",
       "22                    3.0        0.002314   \n",
       "23                   19.0        0.767781   \n",
       "\n",
       "                                              ML path  ML path length  \\\n",
       "0   [Aaron Clauset, Computer science, List of word...            15.0   \n",
       "1   [Linux, Linux Mint, Advanced Packaging Tool, D...            51.0   \n",
       "2   [Wasabi, New Zealand, Unitary state, Niger, Tu...            51.0   \n",
       "3   [Red (Taylor Swift album), Americans, United S...            51.0   \n",
       "4   [Batman, Batman v Superman: Dawn of Justice, D...            51.0   \n",
       "5   [Entropy, Information entropy, Thermodynamic e...            51.0   \n",
       "6   [Brooklyn, New York City, Morgan Stanley, Unit...            51.0   \n",
       "7   [FrÃ©dÃ©ric Chopin, Poland, Christianity, 21st c...            51.0   \n",
       "8   [Rockhole frog, Australia, United States, Fran...             5.0   \n",
       "9   [Peach (color), English language, United State...             9.0   \n",
       "10  [Donald Trump, Australia, United States, Franc...            51.0   \n",
       "11  [Boston Red Sox, Boston, United States, France...            51.0   \n",
       "12  [Infinite Jest, David Foster Wallace, Ithaca, ...            51.0   \n",
       "13  [War of 1812, France, 1953, Pierce Brosnan, Un...            20.0   \n",
       "14  [Bo Burnham, MTV, United States, France, 1953,...            51.0   \n",
       "15  [Orangutan, Singapore, World War I, United Sta...            51.0   \n",
       "16  [Britpop, United States, France, 1953, Pierce ...            51.0   \n",
       "17  [Quantum immortality, SchrÃ¶dinger's cat, Erwin...            51.0   \n",
       "18  [French invasion of Russia, Europe, Middle Age...            40.0   \n",
       "19  [Medieval philosophy, France, 1953, Pierce Bro...            51.0   \n",
       "20  [Cat, Human, United States, France, 1953, Pier...            51.0   \n",
       "21  [Vampire, Buffy the Vampire Slayer, United Sta...            51.0   \n",
       "22  [Magna Carta, BBC, June 27, United States, Fra...            51.0   \n",
       "23  [Jeopardy!, United States, France, 1953, Pierc...            51.0   \n",
       "\n",
       "      ML time                                            RL path  \\\n",
       "0    3.027043  [Aaron Clauset, Physics, List of Jupiter's moo...   \n",
       "1   10.388906  [Linux, List of Linux distributions, Poland, U...   \n",
       "2    6.835197  [Wasabi, Japan, United States, Ronald Reagan, ...   \n",
       "3    8.166886  [Red (Taylor Swift album), Taylor Swift, YouTu...   \n",
       "4    8.481047  [Batman, DC Extended Universe, DC Comics, Unit...   \n",
       "5    9.675905  [Entropy, Thermodynamic entropy, Earth, United...   \n",
       "6    8.174529  [Brooklyn, New York City, United States, Ronal...   \n",
       "7    8.588700  [FrÃ©dÃ©ric Chopin, France, ISO 4217, Country co...   \n",
       "8    1.068968  [Rockhole frog, Australia, United States, Rona...   \n",
       "9    1.892816  [Peach (color), English language, United State...   \n",
       "10   7.298799  [Donald Trump, Bernie Sanders, Ronald Reagan, ...   \n",
       "11   5.804951  [Boston Red Sox, 1912, 1980, 2008, 2006, 2021,...   \n",
       "12   7.746690  [Infinite Jest, David Foster Wallace, American...   \n",
       "13   2.906122  [War of 1812, United States, Ronald Reagan, Ch...   \n",
       "14   8.009554  [Bo Burnham, Comedy Central, United States, Ro...   \n",
       "15   8.782238  [Orangutan, Singapore, March, 2019, 1980, 2008...   \n",
       "16   7.909298  [Britpop, United States, Ronald Reagan, Chicag...   \n",
       "17  10.156051  [Quantum immortality, Copenhagen interpretatio...   \n",
       "18   7.898292  [French invasion of Russia, France, ISO 4217, ...   \n",
       "19  10.258053  [Medieval philosophy, France, ISO 4217, Countr...   \n",
       "20   9.488573  [Cat, Egypt, Christianity, 20th century, 1980,...   \n",
       "21   8.206432  [Vampire, Europe, Russia, United States, Ronal...   \n",
       "22  10.980595                        [Magna Carta, England, DNA]   \n",
       "23   8.677324  [Jeopardy!, United States, Ronald Reagan, Chic...   \n",
       "\n",
       "    RL path length    RL time  \n",
       "0             37.0  26.434564  \n",
       "1             51.0  34.977975  \n",
       "2             51.0  34.508489  \n",
       "3             51.0  33.562705  \n",
       "4             40.0  29.080184  \n",
       "5             51.0  28.869218  \n",
       "6             51.0  29.712728  \n",
       "7             16.0  11.389576  \n",
       "8             11.0   5.244258  \n",
       "9              6.0   1.310228  \n",
       "10            51.0  34.071773  \n",
       "11            51.0  34.457788  \n",
       "12            51.0  25.997787  \n",
       "13            14.0   8.522481  \n",
       "14            51.0  25.384012  \n",
       "15            51.0  23.049131  \n",
       "16            51.0  26.620080  \n",
       "17            51.0  24.397321  \n",
       "18            14.0   5.650933  \n",
       "19            51.0  25.865095  \n",
       "20            51.0  26.358455  \n",
       "21            51.0  24.705460  \n",
       "22             3.0   0.030816  \n",
       "23            21.0  12.835668  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pairs = pd.read_csv('test_pairs.tsv', sep='\\t')\n",
    "\n",
    "# Test pairs\n",
    "max_length = 50\n",
    "for i in tqdm(range(len(pairs))):\n",
    "\tsource = pairs.iloc[i]['Source']\n",
    "\ttarget = pairs.iloc[i]['Target']\n",
    "\n",
    "\t\n",
    "\tfor method in ['Heuristic', 'ML', 'RL']:\n",
    "\t\tif f'{method} path' not in pairs.columns:\n",
    "\t\t\tpairs[f'{method} path'] = 0\n",
    "\t\t\tpairs[f'{method} path'] = pairs[f'{method} path'].astype(object)\n",
    "\t\tstart_time = time.time()\n",
    "\t\tif method == 'Heuristic':\n",
    "\t\t\tpath = navigate(source, target, wiki_game, method='heuristic', max_length=max_length)\n",
    "\t\telif method == 'ML':\n",
    "\t\t\tpath = navigate(source, target, wiki_game, method='ml', model=model, max_length=max_length)\n",
    "\t\telif method == 'RL':\n",
    "\t\t\tpath = navigate(source, target, wiki_game, method='rl', agent=agent, max_length=max_length)\n",
    "\t\tend_time = time.time()\n",
    "\t\t# Add stats to the dataframe\n",
    "\t\tpairs.loc[i, f'{method} path length'] = len(path)\n",
    "\t\tpairs.at[i, f'{method} path'] = path\n",
    "\t\tpairs.loc[i, f'{method} time'] = end_time - start_time\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv('pairs_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
